{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeNrI5euI7U7"
      },
      "outputs": [],
      "source": [
        "#ordinal data - paired tests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#less - average - more\n",
        "#1,2,3,4,5\n",
        "\n",
        "'''\n",
        "Person Before   After\n",
        "A       less    more\n",
        "B       average more\n",
        "C       more    more\n",
        "'''"
      ],
      "metadata": {
        "id": "J3vbaLzvJVLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PirkgUkGLK7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the number of patients\n",
        "num_patients = 20\n",
        "\n",
        "# Generate ordinal data for pain level before and after treatment\n",
        "pain_before = np.random.randint(1, 6, size=num_patients)\n",
        "pain_after = np.random.randint(1, 6, size=num_patients)\n",
        "\n",
        "# Display the generated data\n",
        "print(\"Pain Level Before Treatment:\", pain_before)\n",
        "print(\"Pain Level After Treatment:\", pain_after)\n"
      ],
      "metadata": {
        "id": "KjstIFtuLPPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crosstable\n",
        "data = pandas.DataFrame({\n",
        "    'before': pain_before,\n",
        "    'after':pain_after\n",
        "})\n",
        "\n",
        "crosstable = pandas.crosstab(data['before'], data['after'])\n",
        "crosstable"
      ],
      "metadata": {
        "id": "i9gA9_niMiTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bar chart\n",
        "crosstable.plot(kind='bar')"
      ],
      "metadata": {
        "id": "BPYuCEAtPI2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C8bSv1dEP_aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LIzlm8EK5oY"
      },
      "source": [
        "# Wilcoxon Signed Rank Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfbLIvAK5oc"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fSdxrzRK5od"
      },
      "source": [
        "To test if scores on two paired ordinal variables are evenly distributed there are two tests often mentioned that can be used. Either a two-sample sign test, or a Wilcoxon signed rank test (Wilcoxon, 1945). In both tests the difference between the two variables for each case (respondent) is calculated first. The two-sample sign test then 'simply' checks if the number of positive differences is the same as the number of negative differences (or at least could be in the population). This test ignores the size of the difference, and this is something the Wilcoxon signed rank test does take into consideration to a certain extend. As the name implies it uses ranks to determine if the sum of the ranks is significantly different between the sum of the ranks of the positive differences and of the ranks of the negative differences. I'll use this test for the example.\n",
        "\n",
        "Note that the Wilcoxon test actually removes any ties, i.e. if the score on each variable is the same for a case, it will not be used. Pratt (1959) proposed an alternative method, that does still use these tied scores in the ranking, but it is a lot less known. Another approach might be an partially overlapping samples t-test (Derrick & White, 2018), but although this test might actually be the best to use, this would require to make some more assumptions about the data and is not well-known (yet)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wilcoxon\n",
        "'''\n",
        "H0 - does not have effect\n",
        "Ha - has effect\n",
        "'''"
      ],
      "metadata": {
        "id": "JZnoF-EBQG1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wilcoxon(data['before'], data['after'], correction=False)"
      ],
      "metadata": {
        "id": "2sjPl4NjQKcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statistic=55.5\n",
        "pvalue=0.5111902952338061\n",
        "\n",
        "'''\n",
        "pvalue > 0.05\n",
        "null hypothesis not rejected\n",
        "result not significant which means event does not have an effect on people\n",
        "'''"
      ],
      "metadata": {
        "id": "tCtCl6AkQZZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rosenthal correlation coefficient"
      ],
      "metadata": {
        "id": "hZdYC0Z6RlRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Effect size"
      ],
      "metadata": {
        "id": "dwdC7x4OQ3fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "# Given p-value\n",
        "p_value = 0.5111902952338061\n",
        "\n",
        "# Calculate z-value\n",
        "z_value = norm.ppf(1 - (p_value / 2))\n",
        "\n",
        "print(\"Z-value corresponding to p-value\", p_value, \":\", z_value)"
      ],
      "metadata": {
        "id": "nto5fGRFSn9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "test_statistics = 0.6569854140345461\n",
        "number_of_sample_pairs = data.shape[0]\n",
        "\n",
        "r = abs(test_statistics) / math.sqrt(number_of_sample_pairs)\n",
        "r"
      ],
      "metadata": {
        "id": "G9OWxEOaRm2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Table 1\n",
        "Rosenthal correlation interpretation\n",
        "\n",
        "0.00 < 0.20             very low\n",
        "\n",
        "0.20 < 0.40             low\n",
        "\n",
        "0.40 < 0.60             moderate\n",
        "\n",
        "0.60 < 0.80             strong\n",
        "\n",
        "0.80 < 1.00             very strong\n",
        "\n",
        "Bartz, A. E. (1999). Basic statistical concepts (4th ed). Upper Saddle River, NJ: Merrill.\n",
        "'''"
      ],
      "metadata": {
        "id": "WdO88hEVR9GS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}